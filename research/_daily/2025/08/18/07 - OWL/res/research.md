https://g.co/gemini/share/50738bdb6d52
https://gemini.google.com/app/2f4eeae8172e1401


# GraphRAG
Это более продвинутая версия RAG, которая в качестве источника знаний использует не коллекцию документов, а граф знаний (Knowledge Graph). 
Вместо простого поиска по сходству GraphRAG может выполнять навигацию по связям графа (многошаговый вывод), чтобы собрать более полный и релевантный контекст. 
Например, отвечая на вопрос о лекарстве, система может найти узел лекарства, а затем пройти по связям к узлам, представляющим заболевания, которые оно лечит, и к узлам, описывающим его побочные эффекты. 
Онтология в данном случае определяет схему этого графа.
`H` может использоваться внутри GraphRAG, например, для преобразования вопроса на естественном языке в формальный запрос к графу (например, SPARQL или Cypher) или для структурирования ответа на основе извлеченных из графа данных.

#
Существует целый спектр интеграции структурированных знаний с LLM, и `H` занимает в нем ключевую гибридную позицию. 
Этот спектр можно условно разделить на три уровня:

## Поверхностный (Текстовый) Уровень
На этом уровне находится классический RAG. 
Знания из внешних источников (будь то документы или графы) сериализуются в простой текст и подаются в контекстное окно LLM. 
Структура знаний при этом в значительной степени теряется.

## Гибридный (Символьно-Нейронный) Уровень
Здесь располагается `H`. 
На этом уровне формальная символьная структура (онтология, выраженная в OWL) используется для конструирования текстового промпта, который, в свою очередь, управляет поведением нейронной сети. 
Это гибридный подход, поскольку он использует символьную модель для управления субсимвольной моделью через текстовый интерфейс.

## Глубокий (Суб-Символьный) Уровень
Этот уровень представляют передовые исследовательские методы, такие как инъекция эмбеддингов графа знаний (например, GraphToken) непосредственно во входное векторное пространство LLM. 
Вместо того чтобы описывать структуру графа в тексте, этот метод представляет узлы и ребра графа в виде специальных токенов-эмбеддингов, которые подаются на вход модели наравне с текстовыми токенами. 
Это позволяет LLM «видеть» структуру графа напрямую, без потерь при сериализации в текст.

# 2.3. Методология 3: Прямое встраивание онтологической документации
Третий подход, более простой в реализации, но эффективный для специфических задач, заключается во включении фрагментов онтологии — определений классов и свойств, аксиом или текстовой документации — непосредственно в контекст промпта. 
Цель этого метода — предоставить LLM «основную истину» (ground truth) и нормативную терминологию, на которую модель должна опираться при генерации текста.

